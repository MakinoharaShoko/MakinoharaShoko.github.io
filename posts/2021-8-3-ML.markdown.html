<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/7835419622e5afa0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/7835419622e5afa0.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b3c538488f2d96e9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b3c538488f2d96e9.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-59c5c889f52620d6.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-5020794388548d5e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-9cd66785574873e8.js" defer=""></script><script src="/_next/static/chunks/175675d1-7de8b3bfdcedb0f1.js" defer=""></script><script src="/_next/static/chunks/9f96d65d-c9e0543547ce45e9.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bid%5D-a12bab8c2b2a611d.js" defer=""></script><script src="/_next/static/edEkolaI9vomiF4NWLiqs/_buildManifest.js" defer=""></script><script src="/_next/static/edEkolaI9vomiF4NWLiqs/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="mainLayout_out__ZYqWw" style="height:calc(100vh - var(--vh-offset, 0px))"><div class="mainLayout_mainarea__QxaY0"><div class="post_post__ejhnw"><div class="post_top__JuBkM"><div class="post_b__Bj3sV"><img alt="back" src="/_next/static/media/back.f6d17d78.png" width="480" height="480" decoding="async" data-nimg="1" class="post_bi__9ghX8" loading="lazy" style="color:transparent"/></div><div class="post_tit__Xu2qi">机器学习</div><div class="post_b__Bj3sV"><img alt="close" src="/_next/static/media/close.315313d8.png" width="480" height="480" decoding="async" data-nimg="1" class="post_bi__9ghX8" loading="lazy" style="color:transparent"/></div></div><div class="markdown-body post_md__a6C1y"><h1>入门</h1>
<p>机器学习的基本方法：任务T在得到经验E后提高性能度量P</p>
<h2>监督学习</h2>
<p>监督学习：找正确答案</p>
<p>1、回归问题：找函数，预测连续值</p>
<p>2、分类问题：预测离散值</p>
<h2>无监督学习</h2>
<p>无监督学习：自己找数据的结构和规律（并不提前给出正确答案）</p>
<p>聚类算法：将不同的内容整合为几个集合</p>
<h2>神经网络</h2>
<p>神经网络是一个可以学习模式的函数集合。</p>
<h2>卷积</h2>
<p>通过某种方式处理图像，使之呈现出某种特征</p>
<h2>池化</h2>
<p>处理图像的一种方式，取某些像素的最大、平均值或其他特征值</p>
<h1>TensorFlow</h1>
<h3>实例1：图像分类</h3>
<pre><code class="language-python">import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np

#回调，当准确度达到80%时停止训练
class callBack(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get(&#x27;loss&#x27;)&lt;0.2):
            print(&#x27;\nReached 80%&#x27;)
            self.model.stop_training = True
cb1 = callBack()

#导入Fashion数据集
mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()

#这里的没什么用
plt.imshow(training_images[0])
print(training_images[0])
print((training_labels[0]))

#将像素0-255表示转为更容易处理的0-1表示
training_images = training_images/255
test_images = test_images/255

#升维，以便卷积
training_images = np.expand_dims(training_images, axis=3)
test_images = np.expand_dims(test_images, axis=3)

#神经网络
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64,(3,3),activation=&#x27;relu&#x27;,input_shape=(28,28,1)),#卷积1
    tf.keras.layers.MaxPooling2D(2,2),#最大池化
    tf.keras.layers.Conv2D(64,(3,3),activation=&#x27;relu&#x27;),#卷积2
    tf.keras.layers.MaxPooling2D(2,2),#最大池化
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256,activation=tf.nn.relu),#全连接层
    tf.keras.layers.Dense(10,activation=tf.nn.softmax)]
)

#训练
model.compile(optimizer=tf.optimizers.Adam(),
              loss=&#x27;sparse_categorical_crossentropy&#x27;)
model.summary()
model.fit(training_images,training_labels,epochs=15,
          callbacks=[cb1]
          )

#评估结果
model.evaluate(test_images,test_labels)
</code></pre></div></div></div><div class="mainLayout_bottom__As9s_"><div class="mainLayout_tag__Ep3_f"><img alt="launcher" src="/_next/static/media/launcher.d8f01379.png" width="1024" height="1024" decoding="async" data-nimg="1" class="mainLayout_tagImg__qoDJq" loading="lazy" style="color:transparent"/></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":"---\nlayout:     post\ntitle:      机器学习\nintro:   \"\"\ndate:       2021-8-3 12:00:01\nauthor:     \"Makinohara\"\ncatalog: true\ntags:\n    - 科研应用\n    \n---\n\n# 入门\n\n机器学习的基本方法：任务T在得到经验E后提高性能度量P\n\n## 监督学习\n\n监督学习：找正确答案\n\n1、回归问题：找函数，预测连续值\n\n2、分类问题：预测离散值\n\n## 无监督学习\n\n无监督学习：自己找数据的结构和规律（并不提前给出正确答案）\n\n聚类算法：将不同的内容整合为几个集合\n\n## 神经网络\n\n神经网络是一个可以学习模式的函数集合。\n\n## 卷积\n\n通过某种方式处理图像，使之呈现出某种特征\n\n## 池化\n\n处理图像的一种方式，取某些像素的最大、平均值或其他特征值\n\n# TensorFlow\n\n### 实例1：图像分类\n\n```python\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#回调，当准确度达到80%时停止训练\nclass callBack(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('loss')\u003c0.2):\n            print('\\nReached 80%')\n            self.model.stop_training = True\ncb1 = callBack()\n\n#导入Fashion数据集\nmnist = tf.keras.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n\n#这里的没什么用\nplt.imshow(training_images[0])\nprint(training_images[0])\nprint((training_labels[0]))\n\n#将像素0-255表示转为更容易处理的0-1表示\ntraining_images = training_images/255\ntest_images = test_images/255\n\n#升维，以便卷积\ntraining_images = np.expand_dims(training_images, axis=3)\ntest_images = np.expand_dims(test_images, axis=3)\n\n#神经网络\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),#卷积1\n    tf.keras.layers.MaxPooling2D(2,2),#最大池化\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),#卷积2\n    tf.keras.layers.MaxPooling2D(2,2),#最大池化\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256,activation=tf.nn.relu),#全连接层\n    tf.keras.layers.Dense(10,activation=tf.nn.softmax)]\n)\n\n#训练\nmodel.compile(optimizer=tf.optimizers.Adam(),\n              loss='sparse_categorical_crossentropy')\nmodel.summary()\nmodel.fit(training_images,training_labels,epochs=15,\n          callbacks=[cb1]\n          )\n\n#评估结果\nmodel.evaluate(test_images,test_labels)\n```\n\n"},"__N_SSG":true},"page":"/posts/[id]","query":{"id":"2021-8-3-ML.markdown"},"buildId":"edEkolaI9vomiF4NWLiqs","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>